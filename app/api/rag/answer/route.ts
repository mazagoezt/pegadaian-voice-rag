
export const runtime="nodejs"; export const dynamic="force-dynamic";
import { NextRequest, NextResponse } from "next/server"; import { searchRag } from "@/lib/rag";
export async function POST(req:NextRequest){ const body=await req.json(); const query=String(body?.query||""); if(!query) return NextResponse.json({error:"query required"},{status:400}); const model=process.env.QA_MODEL||"gpt-4o-mini"; try{ const hits=await searchRag(query,6); const context=hits.map((h,i)=>`[#${i+1}] ${h.title}\n---\n${h.snippet}`).join("\n\n").slice(0,12000); const r=await fetch("https://api.openai.com/v1/chat/completions",{method:"POST",headers:{"Authorization":`Bearer ${process.env.OPENAI_API_KEY}","Content-Type":"application/json"},body:JSON.stringify({model,temperature:0.2,messages:[{role:"system",content:"Kamu asisten Pegadaian. Bahasa Indonesia natural. Jawab ringkas hanya dari konteks berikut. Jangan sebutkan URL/sumber."},{role:"user",content:`Pertanyaan: ${query}\n\nKonteks:\n${context}`} ]})}); if(!r.ok){ const err=await r.text(); return NextResponse.json({answer:"Maaf, kendala memproses jawaban.",error:err.slice(0,800)},{status:500}); } const j=await r.json(); const answer=j?.choices?.[0]?.message?.content||"Maaf, belum ada informasi."; return NextResponse.json({answer,source:"rag"}); }catch(e:any){ return NextResponse.json({answer:"Maaf, terjadi kendala.",error:e?.message||String(e)},{status:500}); } }
